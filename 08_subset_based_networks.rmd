---
editor_options: 
  chunk_output_type: console
---

# Finding networks from patch data

**Workflow:**

1. Read in patch data, and link to individual trait data.
2. Remove individuals with traits within 1 SD of the population mean,
and their patches.
3. Find communities in the remaining patches.
4. Filter communities for data quality, and calculate assortativity.
5. Relate assortativity to flock attributes:
  - waterlevel start
  - flock size

## Read in patch data and overlaps

```{r}
# to handle data
library(readr)
library(scales)
library(tidyr); library(tibble)
library(magrittr)
library(dplyr)
library(purrr)
library(stringr)

# to work with networks
library(igraph)

# to plot
library(ggplot2)
library(scico)
```

```{r}
# read in patch data
data_patches <- read_csv("data/data2018/data_2018_patch_summary_has_patches.csv") %>% 
  mutate(uid = as.character(1:nrow(.)))
# read in overlap data
data <- read_csv("data/data2018/data_spatio_temporal_overlap_2018.csv")
```

### Read in trait data

```{r}
# make nodes data -- this the individual identities
# add individual data to patch data
data_id <- readxl::read_excel("data/data2018/Biometrics_2018-2019.xlsx") %>% 
  filter(str_detect(`TAG NR`, "[a-zA-Z]+", negate = TRUE))

# a function for gizzard mass
get_gizzard_mass <- function(x, y) {-1.09 + (3.78*(x*y))}

# add gizzard mass
data_id <- mutate(data_id,
                  gizzard_mass = get_gizzard_mass(SH1, SW1))

# rename columns and drop ids without mass and gizzard mass
data_id <- data_id %>% 
  select(id = `TAG NR`, 
         wing = WING, mass = MASS, 
         gizzard_mass) %>% 
  distinct(id, .keep_all = TRUE) %>% 
  drop_na(gizzard_mass)

# add some exploration scores and tag info
data_behav <- read_csv("data/data2018/2018-19-all_exploration_scores.csv") %>% 
  filter(Exp == "F01")
data_tag <- read_csv("data/data2018/tag_info.csv") %>% 
  mutate(id = as.character(Toa_Tag))

# join all scores
data_id <- left_join(data_id, data_tag,
                     by = c("id")) %>% 
  left_join(data_behav, by = "FB")

# remove ids with no exploration
data_id <- mutate(data_id,
                  behav = Mean) %>% 
  # drop_na(behav) %>% 
  select(id, mass, gizzard_mass, behav)
```

### Filter out small patches

Each fix corresponds to 30s time.

```{r}
data_patches <- filter(data_patches,
                       nfixes > 3)

data <- data %>% 
  filter(patch_i_unique_id %in% data_patches$uid,
         patch_j_unique_id %in% data_patches$uid)
```


## Overlaps in time and space

### When do overlaps happen?

When, in terms of waterlevel, do most overlaps occur?

```{r}
# convert to character
data <- mutate_at(data, vars(contains("patch")), as.character)
data <- left_join(data, data_patches,
                  by = c("patch_i_unique_id" = "uid")) %>% 
  left_join(data_patches,
            by = c("patch_j_unique_id" = "uid"))
```

Count at rounded waterlevel.

```{r}
# round waterlevel start
data_overlap_waterlevel <- data %>% 
  mutate(waterlevel_round = plyr::round_any(waterlevel_start.x, 20)) %>% 
  count(waterlevel_round)

# plot
ggplot(data_overlap_waterlevel)+
  geom_col(aes(x = waterlevel_round, y = n),
           fill = "grey", col = "black")+
  theme_bw()+
  labs(x = "waterlevel (cm NAP)",
       y = "# overlaps",
       caption = "Waterlevel is waterlevel_start.x rounded to 20 cm.",
       title = "# patch overlaps ~ waterlevel")

ggsave(filename = "figs/fig_overlaps_waterlevel.png",
       dpi = 300)
```


### Where do overlaps happen?

Where on the mudflats do overlaps happen?

```{r}
# read griend
griend <- sf::st_read("map.osm", layer = "multipolygons") %>% 
  filter(name %in% c("Richel", "Griend")) %>% 
  sf::st_transform(32631)

# count at x and y
data_overlap_space <- data %>% 
  mutate(x_round = plyr::round_any(x_start.x, 200),
         y_round = plyr::round_any(y_start.x, 200)) %>% 
  count(x_round, y_round)

# plot
ggplot(data_overlap_space)+
  geom_tile(aes(x = x_round, 
                y = y_round,
                fill = n))+
  geom_sf(data = griend,
          fill = NA, size = 1,
          col = "black")+
  scale_fill_scico(trans = "log10", 
                   palette = "lajolla", 
                   values=c(0, 1), 
                   direction = 1,
                   breaks = c(10^c(0:4)))+
  theme_bw()+
  labs(caption = "X and Y are coords_start.x rounded to 200m.",
       title = "# patch overlaps ~ space")

ggsave(filename = "figs/fig_overlaps_space.png",
       dpi = 300)
```

### Where AND when do overlaps happen?

```{r}
# get data
# count at x and y
data_overlap_spacetime <- data %>% 
  mutate(x_round = plyr::round_any(x_start.x, 200),
         y_round = plyr::round_any(y_start.x, 200),
         waterlevel_round = plyr::round_any(waterlevel_start.x, 30)) %>% 
  count(x_round, y_round, waterlevel_round)

# plot
ggplot(data_overlap_spacetime)+
  geom_tile(aes(x = x_round, 
                y = y_round,
                fill = n))+
  geom_sf(data = griend,
          fill = NA, size = 1,
          col = "black")+
  scale_fill_scico(trans = "log10", 
                   palette = "lajolla", 
                   values=c(0, 1), 
                   direction = 1,
                   breaks = c(10^c(0:4)))+
  facet_wrap(~waterlevel_round, labeller = label_both)+
  theme_bw()+
  labs(caption = "X and Y are coords_start.x rounded to 200m.",
       title = "# patch overlaps ~ space")

ggsave(filename = "figs/fig_overlaps_space.png",
       dpi = 300)
```

## Association networks based on space-time overlap subsets

Round each overlap's X, Y and waterlevel coordinates, and construct a network from all overlaps in the same subset of X, Y, time.

```{r}
# make data here
data_overlap <- data %>% 
  mutate(x_round = plyr::round_any(x_start.x, 200),
         y_round = plyr::round_any(y_start.x, 200),
         waterlevel_round = plyr::round_any(waterlevel_start.x, 30))

# select columns
data_overlap <- select(data_overlap,
                       contains("round"),
                       id.x, id.y)

# count interactions among unique pairs
data_overlap <- group_by(data_overlap,
                         x_round, y_round, waterlevel_round) %>% 
  count(id.x, id.y)

# nest in prep for making a network
data_overlap <- nest(data_overlap)

# remove cases where there are fewer than 3 rows
data_overlap <- filter(data_overlap,
                       map_lgl(data, function(x) {
                         nrow(x) >= 3
                       }))
```

Make networks using the edgelist.

```{r}
# make networks for each of the many subsets
data_overlap <- mutate(data_overlap,
                       net = map(data, function(d) { 
                         igraph::graph_from_data_frame(d = d, 
                                                       directed = F)}
                         ))
```

Remove networks with few edges.

```{r}
# duplicate first
network_df <- data_overlap

# count edges
network_df <- mutate(network_df, 
                     n_edges = map_int(net, function(n){
                       E(n) %>% length()
                     })) %>% 
  ungroup()


# remove bad graphs, ie, with fewer than 3 edges
# this is both for quality and practical reasons
min_edges <- 1
min_id <- 2
network_df <- filter(network_df, n_edges > min_edges)
```

# TO DO IS TO ADD VERTEX ATTRIBUTES TO GET TO ASSORTATIVITY

