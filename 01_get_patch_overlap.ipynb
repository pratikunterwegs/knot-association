{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spatio-temporal overlap in patches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Do patches overlap in time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ncls to get faster time overlap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from ncls import NCLS\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# read in the SPATIAL data\n",
    "# because the patch data has some spatials missing\n",
    "# ie patches are described but not made\n",
    "patches = gpd.read_file(\"data/data_2018/spatials/patches_2018.gpkg\")\n",
    "\n",
    "# plot patches for a sanity check\n",
    "# subset = patches.iloc[0:1000]\n",
    "# subset.plot(linewidth=0.5,\n",
    "#             column='id',\n",
    "#             alpha=0.2,\n",
    "#             cmap='tab20b', edgecolor='black')\n",
    "\n",
    "# convert to dataframe, export, and read in again\n",
    "data = pd.DataFrame(patches.drop(columns='geometry'))\n",
    "\n",
    "# assign unique patch id\n",
    "data['uid'] = np.arange(0, data.shape[0])\n",
    "\n",
    "# overwrite data with uid\n",
    "data.to_csv(\"data/data_2018/data_2018_patch_summary_has_patches.csv\",\n",
    "            index=False)\n",
    "\n",
    "# remove from memory\n",
    "del patches\n",
    "\n",
    "# re-read csv data because of integer handling differences\n",
    "data = pd.read_csv(\"data/data_2018/data_2018_patch_summary_has_patches.csv\")\n",
    "# get integer series of start and end times of patches\n",
    "t_start = data['time_start'].astype(np.int64)\n",
    "t_end = data['time_end'].astype(np.int64)\n",
    "t_id = data['uid']\n",
    "\n",
    "# trial ncls\n",
    "# only works on pandas and not geopandas else throws error!\n",
    "# this is very weird behaviour, pd and gpd must differ in int implementation\n",
    "ncls = NCLS(t_start.values, t_end.values, t_id.values)\n",
    "\n",
    "# look at all the overlaps in time\n",
    "# get a dataframe of the overlapping pairs and the extent of overlap\n",
    "data_list = []\n",
    "for i in np.arange(len(t_id)):\n",
    "    ncls = NCLS(t_start[i:].values, t_end[i:].values, t_id[i:].values)\n",
    "    it = ncls.find_overlap(t_start[i],\n",
    "                           t_end[i])\n",
    "    # get the unique patch ids overlapping\n",
    "    overlap_id = []\n",
    "    overlap_extent = []\n",
    "    # get the extent of overlap\n",
    "    for x in it:\n",
    "        overlap_id.append(x[2])\n",
    "        overlap_extent.append(min(x[1], t_end[i]) - max(x[0], t_start[i]))\n",
    "    # add the overlap id for each obs\n",
    "    uid = [i] * len(overlap_id)\n",
    "    # zip the tuples together\n",
    "    tmp_data = list(zip(uid, overlap_id, overlap_extent))\n",
    "    # convert to lists\n",
    "    tmp_data = list(map(list, tmp_data))\n",
    "    tmp_data = list(filter(lambda x: x[0] != x[1], tmp_data))\n",
    "    # tmp_data = tmp_data[tmp_data.uid != tmp_data.overlap_id]\n",
    "    data_list = data_list + tmp_data\n",
    "\n",
    "# concatenate to dataframe\n",
    "data_overlap = pd.DataFrame(data_list,\n",
    "                         columns=['uid', 'overlap_id', 'overlap_extent'])\n",
    "\n",
    "# save data\n",
    "data_overlap.to_csv(\"data/data_2018/data_time_overlaps_patches_2018.csv\", index=False)"
   ]
  },
  {
   "source": [
    "## How much do patches overlap in time?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this section, we quanitify the temporal overlap between individuals\n",
    "# at the global scale, so, how long were two individuals tracked together\n",
    "\n",
    "# read in the data again\n",
    "# group by id and get the first time_start and the final time_end\n",
    "data = pd.read_csv(\"data/data_2018/data_2018_id_tracking_interval.csv\")\n",
    "# get integer series of start and end times of patches\n",
    "t_start = data['time_start'].astype(np.int64)\n",
    "t_end = data['time_end'].astype(np.int64)\n",
    "t_id = data['id']\n",
    "\n",
    "# total overlap\n",
    "data_list = []\n",
    "for i in np.arange(len(t_id)):\n",
    "    ncls = NCLS(t_start[i:].values, t_end[i:].values, t_id[i:].values)\n",
    "    it = ncls.find_overlap(t_start[i],\n",
    "                           t_end[i])\n",
    "    # get the unique patch ids overlapping\n",
    "    overlap_id = []\n",
    "    overlap_extent = []\n",
    "    # get the extent of overlap\n",
    "    for x in it:\n",
    "        overlap_id.append(x[2])\n",
    "        overlap_extent.append(min(x[1], t_end[i]) - max(x[0], t_start[i]))\n",
    "    # add the overlap id for each obs\n",
    "    uid = [t_id[i]] * len(overlap_id)\n",
    "    # zip the tuples together\n",
    "    tmp_data = list(zip(uid, overlap_id, overlap_extent))\n",
    "    # convert to lists\n",
    "    tmp_data = list(map(list, tmp_data))\n",
    "    tmp_data = list(filter(lambda x: x[0] != x[1], tmp_data))\n",
    "    # tmp_data = tmp_data[tmp_data.uid != tmp_data.overlap_id]\n",
    "    data_list = data_list + tmp_data\n",
    "\n",
    "# concatenate to dataframe\n",
    "data_overlap = pd.DataFrame(data_list,\n",
    "                         columns=['uid', 'overlap_id', 'total_simul_tracking'])\n",
    "\n",
    "\n",
    "# write total simul tracking data\n",
    "data_overlap.to_csv(\"data/data_2018/data_2018_id_simul_tracking.csv\", index=False)\n",
    "\n",
    "# wip"
   ]
  },
  {
   "source": [
    "## Which patches overlap in space, and where?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classic python libs\n",
    "import numpy as np\n",
    "\n",
    "# libs for dataframes\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# import ckdtree\n",
    "# from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point, MultiPoint, LineString, MultiLineString, Polygon, MultiPolygon\n",
    "\n",
    "# import ckdtree\n",
    "# from scipy.spatial import cKDTree\n",
    "\n",
    "# import helper functions\n",
    "from helper_functions import simplify_geom, ckd_distance\n",
    "\n",
    "# read in spatial data\n",
    "patches = gpd.read_file(\"data/data_2018/spatials/patches_2018.gpkg\")\n",
    "patches.head()\n",
    "patches.crs = {'init': 'epsg:32631'}\n",
    "\n",
    "# read in temporal overlaps\n",
    "data_overlap = pd.read_csv(\"data/data_2018/data_time_overlaps_patches_2018.csv\")\n",
    "\n",
    "# for each overlap uid/overlap_id get the ckd distance of\n",
    "# the corresponding rows in the spatial\n",
    "spatial_cross = []\n",
    "for i in np.arange(len(data_overlap)):\n",
    "    # get the geometries\n",
    "    g_a = patches.iloc[data_overlap.iloc[i].uid]\n",
    "    g_b = patches.iloc[data_overlap.iloc[i].overlap_id]\n",
    "    covers = g_a.geometry.intersects(g_b.geometry)\n",
    "    spatial_cross.append(covers)\n",
    "\n",
    "# convert to series and add to data frame\n",
    "data_overlap['spatial_overlap'] = pd.Series(spatial_cross)\n",
    "\n",
    "# now that we know which patches overlap in space and time\n",
    "# get the extent of overlap, and the actual overlap object\n",
    "data_overlap = data_overlap[spatial_cross]\n",
    "\n",
    "# in a for loop, add the extent and overlap object\n",
    "overlap_extent = []\n",
    "overlap_obj = []\n",
    "for i in np.arange(len(data_overlap)):\n",
    "    # get the geometries\n",
    "    g_a = patches.iloc[data_overlap.iloc[i].uid]\n",
    "    g_b = patches.iloc[data_overlap.iloc[i].overlap_id]\n",
    "    # get overlap\n",
    "    overlap_polygon = g_a.geometry.intersection(g_b.geometry)\n",
    "    overlap_obj.append(overlap_polygon)\n",
    "    overlap_extent.append(overlap_polygon.area)\n",
    "\n",
    "# add to data\n",
    "data_overlap['spatial_overlap_area'] = np.asarray(overlap_extent)\n",
    "data_overlap['geometry'] = overlap_obj\n",
    "\n",
    "# remove spatial overlap col\n",
    "data_overlap = data_overlap.drop(columns='spatial_overlap')\n",
    "\n",
    "# make geodataframe\n",
    "overlap_spatials = gpd.GeoDataFrame(data_overlap, geometry=data_overlap['geometry'])\n",
    "\n",
    "# save into spatails\n",
    "overlap_spatials.to_file(\"data/data_2018/spatials/patch_overlap_2018.gpkg\", layer='overlaps',\n",
    "                         driver=\"GPKG\")\n",
    "\n",
    "# save to csv\n",
    "data_overlap = pd.DataFrame(overlap_spatials.drop(columns = 'geometry'))\n",
    "data_overlap = data_overlap.rename(columns={\"overlap_extent\":\"temporal_overlap_seconds\",\n",
    "                                            \"uid\":\"patch_i_unique_id\",\n",
    "                                            \"overlap_id\":\"patch_j_unique_id\"})\n",
    "\n",
    "# write to file\n",
    "data_overlap.to_csv(\"data/data_2018/data_spatio_temporal_overlap_2018.csv\", index=False)\n",
    "\n",
    "# ends here"
   ]
  }
 ]
}