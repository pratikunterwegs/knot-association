# Summary stats for paper

# Attribution

Code author Pratik Gupte
PhD student
MARM group, GELIFES-RUG, NL
Contact p.r.gupte@rug.nl

```{r setup}
library(knitr)
opts_knit$set(root.dir=normalizePath('../'))
```

```{r load_data}
#### code to summarise various data ####

library(data.table); library(tidyverse); library(glue)
library(fasttime)

# plot theme
source("../knots_code/codePlotOptions/ggThemeKnots.r")

# read in data and add tidal cycles
dataFiles <- list.files(path = "../data2018/oneHertzData/", full.names = TRUE, pattern = "csv")
```

```{r summarise_totaldata}
# check total data collected
dataSummary <- map_df(dataFiles, function(z){
  setDF(fread(z)[,.(startTime = min(TIME),
              endTime = max(TIME),
              fixes = length(X),
              id = as.character(unique(TAG - 3.1001e10)))])
})

```

```{r count_fix_per_bird}
# check for fixes order of magnitude
count(dataSummary, fixLog = floor(log10(fixes)))

# count total number of fixes
sum(dataSummary$fixes)
```

```{r get_tracking_duration}
# get range of time as posixct
diff(as.POSIXct(range(c(dataSummary$startTime, dataSummary$endTime)), origin = "1970-01-01", tz = "Europe/Berlin"))
```

```{r read_behavdata}
# read in behavioural scores for release times
behavData <- fread("../data2018/behavScores.csv")[,`:=`(Release_Date=as.POSIXct(Release_Date),
                                                        id=as.character(id))] %>% 
  as_tibble()
```

```{r count_transmit_fore_release}
# how many transmitting before release
dataSummary = inner_join(dataSummary, behavData) %>% 
  distinct(id, .keep_all = T)
count(dataSummary, transmittingBeforeRelease = startTime < as.numeric(Release_Date))

# count how many positions removed
recPrepFiles <- list.files("../data2018/oneHertzData/recursePrep/", full.names = T)

# read in data and ask how many rows
recPrepData <- map_df(recPrepFiles, function(z){
  fread(z)[,.(startTime = min(time),
               endTime = max(time),
               fixes = length(x)),by=list(id, tidalcycle)]
})
```

```{r fixes_days_tracked}
# get number of fixes and days tracked
recPrepDataSummary <- recPrepData %>% 
  group_by(id) %>% 
  mutate_at(vars(contains("Time")), list(~as.POSIXct(., origin = "1970-01-01"))) %>% 
  summarise(fixes = sum(fixes), duration = (max(endTime) - min(startTime)))

sum(recPrepData$fixes)
```

```{r track_area}
# get tracking area
boundPoly <- st_read("../data2018/spatials/newUnionPatches/unionPatches.shp")

st_area(boundPoly)
```


```{r get_relweek_wise_fixes}
# get mean per release week
dataSummary <- recPrepDataSummary %>%
  mutate(id = as.character(id)) %>% 
  inner_join(dataSummary %>% mutate(relWeek = week(Release_Date)) %>% 
               select(id, relWeek)) %>% 
  group_by(relWeek) %>% 
  summarise_at(vars(fixes, duration), list(~mean(.), ~sd(.), ~min(.), ~max(.), ~length(.))) %>% 
  mutate(fixesPerDay = fixes_mean/as.numeric(duration_mean))
```

```{r}
dataSummary %>% 
  summarise_at(vars(fixesPerDay), list(~mean(.), ~sd(.), ~min(.), ~max(.)))
```


```{r check_differences_fixperday}
# use an anova
summary(aov(fixesPerDay ~ relWeek, data = dataSummary))

```

```{r west_terschelling_harbour}
# where is west terschelling
# taken from wikipedia, which links to the correct location on OSM
# https://tools.wmflabs.org/geohack/geohack.php?language=nl&params=53_021_039_N_5_012_056_E_type:city_scale:25000_region:NL&pagename=West-Terschelling

terschelling <- c(5.215556, 53.360833) %>% 
  st_point() %>% st_sfc() %>% `st_crs<-`(4326) %>% st_transform(32631)

# read griend and find distance
griend <- st_read("../griend_polygon/griend_polygon.shp")

st_distance(terschelling, st_centroid(griend))
```

```{r ht_data}
# when
tides <- read_csv("../data2018/tidesSummer2018.csv") %>% filter(tide == "H")

max(recPrepData$tidalcycle)
```

```{r tides_per_bird}
# how many tides per id on average
recPrepData %>% 
  count(id, name = "tides") %>% 
  summarise_at(vars(tides), list(~mean(.), ~sd(.), ~min(.), ~max(.)))

# plot hist tides per id
tidesPerId <- count(recPrepData, id, name = "tides")

figHistTidesId <- ggplot()+
  geom_histogram(data = tidesPerId, aes(x = tides), fill = stdGry, col = 1)+
  geom_vline(xintercept = c(10, 20, 60, 120), col = 2, lty = 2)+
  geom_text(aes(x = c(10, 20, 60, 120), y = 15, label = c("5 days", "10 days", "1 month", "2 months")), nudge_x = -2, angle = 90)+
  themePubKnots()+
  labs(x = "Tidal cycles", y = "Number of individuals")

ggsave(figHistTidesId, filename = "../figs/figHistTidesId.pdf",
       device = pdf(), height = 4, width = 6, units = "in")

```

# distance and mcp stuff

**see `code_coarseMetStats.r` for model output**

```{r read_dist_mcp}
# read in data
mcpArea <- fread("../data2018/oneHertzData/summary/dataMCParea.csv")

# summarise mcp area and distance overall
mcpArea %>% 
  summarise_at(vars(totalDist, mcpArea),
               list(~mean(.), ~sd(.), ~min(.), ~quantile(., probs = 0.95))) %>% 
  mutate_at(vars(contains('mcp')), list(function(z){z/1000^2}))
```

# patch metrics and explore score

```{r load_patch_data etc}
# read in patch data
patches <- read_csv("../data2018/oneHertzData/summary/data2018patches.csv") 

# read in behav scores
behavScore <- read_csv("../data2018/behavScores.csv")

# link behav score and patch size and area
patches <- full_join(patches, behavScore, by= c("id"))

# write to file a table of whether there is movement data and explore data or not
useableData <- patches %>% 
  group_by(id) %>% 
  mutate(moveData = ifelse(!is.na(max(resPatch)), "yes", "no"),
         exploreScore = ifelse(is.numeric(exploreScore) & !is.nan(exploreScore), "yes", "no")) %>% 
  select(id, exploreScore, moveData) %>% 
  distinct()

# writing
fwrite(useableData, file = "../data2018/data2018idsWithData.csv")
```

```{r basic_patch_stats}
# nrow patches
nrow(patches)

# avg N patches
patches %>% 
  filter(nFixes > 0) %>% 
  count(id, tidalcycle) %>% 
  summarise_at(vars(n), list(~mean(.), ~sd(.), ~min(.), ~max(.), ~quantile(., probs = 0.95)))
```

```{r compare_scales}
# compare large and small scale polygons
comparePatches <- left_join(mcpArea,
                            patches %>% group_by(id, tidalcycle) %>% 
                              summarise_at(vars(nFixes, area), list(sum)))

# get difference
comparePatches %>% 
  mutate(area = area/1e6, mcpArea = mcpArea/1e6,
    areaRatio = (area/mcpArea)) %>% 
  filter(!is.na(areaRatio), !is.infinite(areaRatio)) %>% 
  summarise_at(vars(area, areaRatio), list(~mean(.), ~sd(.), ~min(.), ~max(.), ~quantile(., probs = 0.95)))
```

```{r summarise_metrics}
# summarise patch metrics
patches %>% 
  select(nFixes, duration, distInPatch, distBwPatch,area) %>% 
  drop_na() %>% 
  gather(var, value) %>% 
  group_by(var) %>% 
  summarise_all(list(~mean(.), ~sd(.), ~min(.), ~max(.), ~quantile(., probs = 0.95, na.rm = T)))

```

