[
["index.html", "Linking experimental measures of personality to free-living space-use in red knots 1 Introduction 1.1 Attribution 1.2 Data access 1.3 Data processing", " Linking experimental measures of personality to free-living space-use in red knots Pratik R Gupte 2019-12-03 1 Introduction This is the bookdown version of a project in preparation that links high-resolution tracking data from individual red knots Calidris canutus islandica to fine-scale experimental behaviour measurements in captivity, and aims to explore whether free-living space-use can be predicted by lab assays of consistent individual differences. 1.1 Attribution Please contact the following before cloning or in case of interest in the project. Pratik Gupte (author and maintainer) PhD student, GELIFES – University of Groningen Guest researcher, COS – NIOZ p.r.gupte@rug.nl Nijenborgh 7/5172.0583 9747AG Groningen Allert Bijleveld (PI): allert.bijleveld@nioz.nl Project information: https://www.nioz.nl/en/about/cos/coastal-movement-ecology/shorebird-tracking Selin Ersoy (collab): selin.ersoy@nioz.nl 1.2 Data access The data used in this work are not publicly available. Contact PI Allert Bijleveld for data access. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],
["getting-data.html", "2 Getting data 2.1 Prepare watlasUtils and other libraries 2.2 Read in tag deployment data 2.3 Get data and save locally", " 2 Getting data This section focusses on accessing and downloading WATLAS data. This is done using functions in the WATLAS Utilities package. Workflow Preparing required libraries. Reading tag data with deployment start dates from a local file. This file is not yet publicly available. Connecting to the NIOZ databse and downloading data. This database is also not public-access. 2.1 Prepare watlasUtils and other libraries # install the package watlasUtils from master branch using the following # install.packages(&quot;devtools&quot;) library(devtools) # devtools::install_github(&quot;pratikunterwegs/watlasUtils&quot;) library(watlasUtils) # libraries to process data library(data.table) library(ggplot2) library(ggthemes) library(purrr) library(glue) 2.2 Read in tag deployment data # read deployment data from local file in data folder tag_info &lt;- fread(&quot;data/data2018/SelinDB.csv&quot;) # filter out NAs in release date and time tag_info &lt;- tag_info[!is.na(Release_Date) &amp; !is.na(Release_Time),] # make release date column as POSIXct tag_info[,Release_Date := as.POSIXct(paste(Release_Date, Release_Time, sep = &quot; &quot;), format = &quot;%d.%m.%y %H:%M&quot;, tz = &quot;CET&quot;)] # check new release date column head(tag_info$Release_Date) ## [1] &quot;2018-09-14 20:00:00 CEST&quot; ## [2] &quot;2018-09-13 15:30:00 CEST&quot; ## [3] &quot;2018-09-14 20:00:00 CEST&quot; ## [4] &quot;2018-09-13 18:30:00 CEST&quot; ## [5] &quot;2018-08-11 15:00:00 CEST&quot; ## [6] &quot;2018-08-16 18:04:00 CEST&quot; (#fig:plot_release_schedule)Knots released per week of 2018. 2.3 Get data and save locally # read in database access parameters from a local file data_access &lt;- fread(&quot;data/access_params.txt&quot;) # create a data storage file if not present # use the getData function from watlasUtils on the tag_info data frame # this is placed inside a pmap wrapper to automate access for all birds if(!dir.exists(&quot;data/data2018&quot;)) { dir.create(&quot;data/data2018&quot;) } pmap(tag_info[,.(Toa_Tag, Release_Date)], function(Toa_Tag, Release_Date){ prelim_data &lt;- watlasUtils::funcGetData(tag = Toa_Tag, tracking_time_start = as.character(Release_Date), tracking_time_end = &quot;2018-10-31&quot;, username = data_access$username, password = data_access$password) print(glue(&#39;tag {Toa_Tag} accessed with {nrow(prelim_data)} fixes&#39;)) fwrite(prelim_data, file = glue(&#39;data/data2018/{Toa_Tag}_raw.csv&#39;), dateTimeAs = &quot;epoch&quot;) }) "],
["cleaning-data.html", "3 Cleaning data 3.1 Prepare watlasUtils and other libraries 3.2 Read, clean, and write data", " 3 Cleaning data This section is about cleaning downloaded data using the cleanData function in the WATLAS Utilities package. Workflow Prepare required libraries. Read in data, apply the cleaning function, and overwrite local data. 3.1 Prepare watlasUtils and other libraries # watlasUtils assumed installed from the previous step # if not, install from the github repo as shown below # devtools::install_github(&quot;pratikunterwegs/watlasUtils&quot;) library(watlasUtils) # libraries to process data library(data.table) library(purrr) library(glue) 3.2 Read, clean, and write data # make a list of data files to read data_files &lt;- list.files(path = &quot;data/data2018/&quot;, pattern = &quot;_raw.csv&quot;, full.names = TRUE) # map read in, cleaning, and write out function over vector of filenames map(data_files, function(df){ temp_data &lt;- fread(df) clean_data &lt;- watlasUtils::funcCleanData(somedata = temp_data, moving_window = 5, nbs_min = 0, sd_threshold = 5e5, plot = FALSE) print(glue(&#39;tag {Toa_Tag} cleaned with {nrow(clean_data)} fixes&#39;)) fwrite(x = clean_data, file = df, dateTimeAs = &quot;epoch&quot;) rm(df); gc() }) "],
["adding-tidal-cycle-data.html", "4 Adding tidal cycle data 4.1 Prepare watlasUtils and other libraries 4.2 Read water level data 4.3 Calculate high tides", " 4 Adding tidal cycle data This section is about adding tidal cycle data to individual trajectories. This is done to split the data up into convenient, and biologically sensible units. This section uses the package VulnToolkit to identify high tide times from water-level data provided by Rijkswaterstaat for the measuring point at West Terschelling. Workflow Prepare required libraries, Read in water level data and identify high tides, Write tidal cycle data to local file, Add tidal cycle time to movement data. 4.1 Prepare watlasUtils and other libraries # load VulnToolkit or install if not available if(&quot;VulnToolkit&quot; %in% installed.packages() == FALSE){ devtools::install_github(&quot;troyhill/VulnToolkit&quot;) } library(VulnToolkit) # libraries to process data library(data.table) library(purrr) library(glue) 4.2 Read water level data Water level data for West Terschelling, a settlement approx. 10km from the field site are provided by Rijkswaterstaat’s Waterinfo, in cm above Amsterdam Ordnance Datum. These data are manually downloaded in the range July 1, 2018 – October 31, 2018 and saved in data/data2018. # read in waterlevel data waterlevel &lt;- fread(&quot;data/data2018/waterlevelWestTerschelling.csv&quot;, sep = &quot;;&quot;) # select useful columns and rename waterlevel &lt;- waterlevel[,.(WAARNEMINGDATUM, WAARNEMINGTIJD, NUMERIEKEWAARDE)] setnames(waterlevel, c(&quot;date&quot;, &quot;time&quot;, &quot;level&quot;)) # make a single POSIXct column of datetime waterlevel[,dateTime := as.POSIXct(paste(date, time, sep = &quot; &quot;), format = &quot;%d-%m-%Y %H:%M:%S&quot;)] 4.3 Calculate high tides A tidal period of 12 hours 25 minutes is taken from Rijkswaterstaat. # use the HL function from vulnToolkit to get high tides tides = VulnToolkit::HL(waterlevel$level, waterlevel$dateTime, period = 12.41, tides = &quot;H&quot;, semidiurnal = FALSE) # write to local file fwrite(tide, file = &quot;data/data2018/tidesSummer2018.csv&quot;, dateTimeAs = &quot;epoch&quot;) "]
]
